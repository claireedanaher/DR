{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "heading_collapsed": true,
    "id": "iLlMCqgzx9N1"
   },
   "source": [
    "# LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "YDxBkSjnx9N3"
   },
   "outputs": [],
   "source": [
    "## import torch\n",
    "import torchvision\n",
    "import torch\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "import numpy as np\n",
    "from torch.nn import functional as F\n",
    "import time\n",
    "import pandas as pd \n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "heading_collapsed": true,
    "id": "JIMbMDlZx9N8"
   },
   "source": [
    "# Pull in MNIST Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "9ftUtu11x9N9"
   },
   "source": [
    "## MNIST Data Label Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "LwAxqMBqx9N-"
   },
   "outputs": [],
   "source": [
    "def gen_mnist():\n",
    "    from sklearn.datasets.base import get_data_home \n",
    "    from sklearn.datasets import fetch_mldata\n",
    "    print (get_data_home())\n",
    "    mnist_raw = fetch_mldata('MNIST original', data_home=get_data_home())\n",
    "    mnist=mnistData(mnist_raw.target,mnist_raw.data) \n",
    "    cnt=len(mnist.label)\n",
    "    labelset=torch.tensor(mnist.label)\n",
    "    labelset.shape\n",
    "    dataset=torch.tensor(mnist.x,dtype=torch.float)\n",
    "    number_columns=dataset.shape[1]\n",
    "    dataset = dataset.view(-1,number_columns).float()/256.0\n",
    "    print(dataset.shape)\n",
    "    dataset=dataset.view(cnt,28,28)\n",
    "    return(labelset, dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "heading_collapsed": true,
    "id": "vfpnBQRSx9OD"
   },
   "source": [
    "# Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "heading_collapsed": true,
    "hidden": true,
    "id": "lt6PFBNzx9OF"
   },
   "source": [
    "## Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "wnWZNlU5x9OG"
   },
   "outputs": [],
   "source": [
    "## CUSTOM DATA LOADER\n",
    "from torch.utils.data.dataset import Dataset\n",
    "class rgenData(Dataset):\n",
    "    def __init__(self, randEnc, x, transform=None):\n",
    "        self.randEnc= randEnc\n",
    "        self.x=x \n",
    "    def __len__(self):\n",
    "        z=self.x.shape[0]\n",
    "        return  z\n",
    "    def __getitem__(self, idx):\n",
    "        randEnc=self.randEnc[idx]\n",
    "        x=self.x[idx]\n",
    "        return randEnc, x\n",
    "\n",
    "## CUSTOM DATA LOADER\n",
    "from torch.utils.data.dataset import Dataset\n",
    "class mnistData(Dataset):\n",
    "    def __init__(self, label, x, transform=None):\n",
    "        self.label= label\n",
    "        self.x=x \n",
    "    def __len__(self):\n",
    "        z=self.x.shape[0]\n",
    "        return  z\n",
    "    def __getitem__(self, idx):\n",
    "        label=self.label[idx]\n",
    "        x=self.x[idx]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "Idjkh72Hx9OK"
   },
   "source": [
    "## 2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "o7Nkmua4x9OM"
   },
   "source": [
    "### Decoder 1L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "LUmNgknmx9ON"
   },
   "outputs": [],
   "source": [
    "#############################################################################################################\n",
    "###\n",
    "# PYTORCH DOCUMENTATION EXAMPLE\n",
    "# TUTORIAL USED: #https://github.com/MorvanZhou/PyTorch-Tutorial/blob/master/tutorial-contents/404_autoencoder.py\n",
    "###\n",
    "#### HYPER PARAMS\n",
    "LR = 0.0005         # learning rate\n",
    "N_TEST_IMG = 5\n",
    "\n",
    "class Decoder_1L_2D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder_1L_2D, self).__init__()\n",
    "        ###########################\n",
    "        #What is this used for?\n",
    "        #self.map = {}\n",
    "        ###########################\n",
    "        self.fc4 = nn.Linear(2, 784)\n",
    "\n",
    "        \n",
    "    def decode(self, z):\n",
    "        out=self.fc4(z)\n",
    "        return torch.sigmoid(out)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        encoded = x\n",
    "        #decoded= x\n",
    "        decoded = self.decode(encoded)\n",
    "        return encoded, decoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "0EOKvMLLx9OR"
   },
   "source": [
    "### Decoder 2L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "WrjdbffWx9OS"
   },
   "outputs": [],
   "source": [
    "#############################################################################################################\n",
    "###\n",
    "# PYTORCH DOCUMENTATION EXAMPLE\n",
    "# TUTORIAL USED: #https://github.com/MorvanZhou/PyTorch-Tutorial/blob/master/tutorial-contents/404_autoencoder.py\n",
    "###\n",
    "#### HYPER PARAMS\n",
    "LR = 0.0005         # learning rate\n",
    "N_TEST_IMG = 5\n",
    "\n",
    "class Decoder_2L_2D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder_2L_2D, self).__init__()\n",
    "        ###########################\n",
    "        #What is this used for?\n",
    "        #self.map = {}\n",
    "        ###########################\n",
    "        self.fc4 = nn.Linear(2, 100)\n",
    "        self.sig = nn.Sigmoid()\n",
    "        self.fc5 = nn.Linear(100, 784)\n",
    "\n",
    "        \n",
    "    def decode(self, z):\n",
    "        out=self.fc4(z)\n",
    "        out2=self.sig(out)\n",
    "        out3=self.fc5(out2)\n",
    "        out4=self.sig(out3)\n",
    "        return out4\n",
    "    \n",
    "    def forward(self, x):\n",
    "        encoded = x\n",
    "        #decoded= x\n",
    "        decoded = self.decode(encoded)\n",
    "        return encoded, decoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "jIlTSM3Dx9OW"
   },
   "source": [
    "### Decoder 3L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "regGnWPFx9OX"
   },
   "outputs": [],
   "source": [
    "###\n",
    "# PYTORCH DOCUMENTATION EXAMPLE\n",
    "# TUTORIAL USED: #https://github.com/MorvanZhou/PyTorch-Tutorial/blob/master/tutorial-contents/404_autoencoder.py\n",
    "###\n",
    "#### HYPER PARAMS\n",
    "LR = 0.0005         # learning rate\n",
    "N_TEST_IMG = 5\n",
    "\n",
    "class Decoder_3L_2D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder_3L_2D, self).__init__()\n",
    "        ###########################\n",
    "        #What is this used for?\n",
    "        #self.map = {}\n",
    "        ###########################\n",
    "        self.fc4 = nn.Linear(2, 100)\n",
    "        self.sig = nn.Sigmoid()\n",
    "        self.fc5 = nn.Linear(100, 200)\n",
    "        self.fc6 = nn.Linear(200, 784)\n",
    "\n",
    "        \n",
    "    def decode(self, z):\n",
    "        out=self.fc4(z)\n",
    "        out2=self.sig(out)\n",
    "        out3=self.fc5(out2)\n",
    "        out4=self.sig(out3)\n",
    "        out5=self.fc6(out4)\n",
    "        out6=self.sig(out5)\n",
    "        return out6\n",
    "    \n",
    "    def forward(self, x):\n",
    "        encoded = x\n",
    "        #decoded= x\n",
    "        decoded = self.decode(encoded)\n",
    "        return encoded, decoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "j_z5-blKx9Oc"
   },
   "source": [
    "### Decoder 4L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "1EBf5rYux9Oe"
   },
   "outputs": [],
   "source": [
    "#############################################################################################################\n",
    "###\n",
    "# PYTORCH DOCUMENTATION EXAMPLE\n",
    "# TUTORIAL USED: #https://github.com/MorvanZhou/PyTorch-Tutorial/blob/master/tutorial-contents/404_autoencoder.py\n",
    "###\n",
    "#### HYPER PARAMS\n",
    "LR = 0.0005         # learning rate\n",
    "N_TEST_IMG = 5\n",
    "\n",
    "class Decoder_4L_2D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder_4L_2D, self).__init__()\n",
    "        ###########################\n",
    "        #What is this used for?\n",
    "        #self.map = {}\n",
    "        ###########################\n",
    "        self.fc4 = nn.Linear(2, 100)\n",
    "        self.sig = nn.Sigmoid()\n",
    "        self.fc5 = nn.Linear(100, 200)\n",
    "        self.fc6 = nn.Linear(200, 300)\n",
    "        self.fc7 = nn.Linear(300, 784)\n",
    "\n",
    "        \n",
    "    def decode(self, z):\n",
    "        out=self.fc4(z)\n",
    "        out2=self.sig(out)\n",
    "        out3=self.fc5(out2)\n",
    "        out4=self.sig(out3)\n",
    "        out5=self.fc6(out4)\n",
    "        out6=self.sig(out5)\n",
    "        out7=self.fc7(out6)\n",
    "        out8=self.sig(out7)\n",
    "        return out8\n",
    "    \n",
    "    def forward(self, x):\n",
    "        encoded = x\n",
    "        #decoded= x\n",
    "        decoded = self.decode(encoded)\n",
    "        return encoded, decoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "l2VZpf9ex9Oj"
   },
   "source": [
    "### AE_2L2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "qbUSv3fTx9Ok"
   },
   "outputs": [],
   "source": [
    "#############################################################################################################\n",
    "###\n",
    "# PYTORCH DOCUMENTATION EXAMPLE\n",
    "# TUTORIAL USED: #https://github.com/MorvanZhou/PyTorch-Tutorial/blob/master/tutorial-contents/404_autoencoder.py\n",
    "###\n",
    "#### HYPER PARAMS\n",
    "LR = 0.0005         # learning rate\n",
    "\n",
    "class AE_2L2D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AE_2L2D, self).__init__()\n",
    "        ###########################\n",
    "        #What is this used for?\n",
    "        #self.map = {}\n",
    "        ###########################\n",
    "        self.sig = nn.Sigmoid()\n",
    "        self.bc4 = nn.Linear(2, 100)\n",
    "        self.bc5 = nn.Linear(100, 784)\n",
    "\n",
    "\n",
    "        self.fw4 = nn.Linear(784, 100)\n",
    "        self.fw5 = nn.Linear(100, 2)\n",
    "        \n",
    "    def encode(self, z):\n",
    "        enc=self.fw4(z)\n",
    "        enc2=self.sig(enc)\n",
    "        enc3= self.fw5(enc2)\n",
    "        enc4=self.sig(enc3)   \n",
    "        return enc4\n",
    "        \n",
    "    \n",
    "    def decode(self, z):\n",
    "        out=self.bc4(z)\n",
    "        out2=self.sig(out)\n",
    "        out3=self.bc5(out2)\n",
    "        out4=self.sig(out3)\n",
    "        return out4\n",
    "    \n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encode(x)\n",
    "        decoded = self.decode(encoded)\n",
    "        return encoded, decoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "sI64h9yjx9Oo"
   },
   "source": [
    "### AE 1L2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "jiSq-ZEWx9Op"
   },
   "outputs": [],
   "source": [
    "#############################################################################################################\n",
    "###\n",
    "# PYTORCH DOCUMENTATION EXAMPLE\n",
    "# TUTORIAL USED: #https://github.com/MorvanZhou/PyTorch-Tutorial/blob/master/tutorial-contents/404_autoencoder.py\n",
    "###\n",
    "#### HYPER PARAMS\n",
    "LR = 0.0005         # learning rate\n",
    "\n",
    "class AE_1L2D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AE_1L2D, self).__init__()\n",
    "        ###########################\n",
    "        #What is this used for?\n",
    "        #self.map = {}\n",
    "        ###########################\n",
    "        self.fw4 = nn.Linear(784, 2)\n",
    "        self.bc4 = nn.Linear(2, 784)\n",
    "        \n",
    "    def encode(self, z):\n",
    "        enc=self.fw4(z)\n",
    "        return torch.sigmoid(enc)\n",
    "        \n",
    "    \n",
    "    def decode(self, z):\n",
    "        out=self.bc4(z)\n",
    "        return torch.sigmoid(out)\n",
    "    \n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encode(x)\n",
    "        decoded = self.decode(encoded)\n",
    "        return encoded, decoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "nj0L46z2x9Ot"
   },
   "source": [
    "### AE 3L2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "YibQ-tsCx9Ov"
   },
   "outputs": [],
   "source": [
    "#############################################################################################################\n",
    "###\n",
    "# PYTORCH DOCUMENTATION EXAMPLE\n",
    "# TUTORIAL USED: #https://github.com/MorvanZhou/PyTorch-Tutorial/blob/master/tutorial-contents/404_autoencoder.py\n",
    "###\n",
    "#### HYPER PARAMS\n",
    "LR = 0.0005         # learning rate\n",
    "\n",
    "class AE_3L2D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AE_3L2D, self).__init__()\n",
    "        ###########################\n",
    "        #What is this used for?\n",
    "        #self.map = {}\n",
    "        ###########################\n",
    "        self.bc4 = nn.Linear(2, 100)\n",
    "        self.sig = nn.Sigmoid()\n",
    "        self.bc5 = nn.Linear(100, 200)\n",
    "        self.bc6 = nn.Linear(200, 784)\n",
    "        self.fw4 = nn.Linear(784, 200)\n",
    "        self.fw5 = nn.Linear(200, 100)\n",
    "        self.fw6 = nn.Linear(100, 2)\n",
    "        \n",
    "    def encode(self, z):\n",
    "        enc=self.fw4(z)\n",
    "        enc2=self.sig(enc)\n",
    "        enc3= self.fw5(enc2)\n",
    "        enc4=self.sig(enc3)   \n",
    "        enc5=self.fw6(enc4)   \n",
    "        enc6=self.sig(enc5)   \n",
    "        return enc6\n",
    "        \n",
    "    \n",
    "    def decode(self, z):\n",
    "        out=self.bc4(z)\n",
    "        out2=self.sig(out)\n",
    "        out3=self.bc5(out2)\n",
    "        out4=self.sig(out3)\n",
    "        out5=self.bc6(out4)\n",
    "        out6=self.sig(out5)\n",
    "        return out6\n",
    "    \n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encode(x)\n",
    "        decoded = self.decode(encoded)\n",
    "        return encoded, decoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "-zJVzGKTx9O3"
   },
   "source": [
    "### AE 4L2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "9B07GhbQx9O4"
   },
   "outputs": [],
   "source": [
    "#############################################################################################################\n",
    "###\n",
    "# PYTORCH DOCUMENTATION EXAMPLE\n",
    "# TUTORIAL USED: #https://github.com/MorvanZhou/PyTorch-Tutorial/blob/master/tutorial-contents/404_autoencoder.py\n",
    "###\n",
    "#### HYPER PARAMS\n",
    "LR = 0.0005         # learning rate\n",
    "\n",
    "class AE_4L2D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AE_4L2D, self).__init__()\n",
    "        ###########################\n",
    "        #What is this used for?\n",
    "        #self.map = {}\n",
    "        ###########################\n",
    "        self.fw4 = nn.Linear(784, 300)\n",
    "        self.fw5 = nn.Linear(300, 200)\n",
    "        self.fw6 = nn.Linear(200, 100)\n",
    "        self.fw7 = nn.Linear(100, 2)\n",
    "        self.sig = nn.Sigmoid()\n",
    "        self.bc4 = nn.Linear(2, 100)        \n",
    "        self.bc5 = nn.Linear(100, 200)\n",
    "        self.bc6 = nn.Linear(200, 300)\n",
    "        self.bc7 = nn.Linear(300, 784)\n",
    "\n",
    "\n",
    "    def encode(self, z):\n",
    "        enc=self.fw4(z)\n",
    "        enc2=self.sig(enc)\n",
    "        enc3= self.fw5(enc2)\n",
    "        enc4=self.sig(enc3) \n",
    "        enc5= self.fw6(enc4)\n",
    "        enc6=self.sig(enc5)  \n",
    "        enc7= self.fw7(enc6)\n",
    "        enc8=self.sig(enc7)  \n",
    "        return enc8\n",
    "        \n",
    "    \n",
    "    def decode(self, z):\n",
    "        out=self.bc4(z)\n",
    "        out2=self.sig(out)\n",
    "        out3= self.bc5(out2)\n",
    "        out4=self.sig(out3) \n",
    "        out5= self.bc6(out4)\n",
    "        out6=self.sig(out5)  \n",
    "        out7= self.bc7(out6)\n",
    "        out8=self.sig(out7)  \n",
    "        return out8\n",
    "    \n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encode(x)\n",
    "        decoded = self.decode(encoded)\n",
    "        return encoded, decoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "cqjsRdI2x9O8"
   },
   "source": [
    "## 6D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "uPzC_wyHx9O9"
   },
   "source": [
    "### Decoder 1L6D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "code_folding": [],
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "4JoYhsMbx9O-"
   },
   "outputs": [],
   "source": [
    "#############################################################################################################\n",
    "###\n",
    "# PYTORCH DOCUMENTATION EXAMPLE\n",
    "# TUTORIAL USED: #https://github.com/MorvanZhou/PyTorch-Tutorial/blob/master/tutorial-contents/404_autoencoder.py\n",
    "###\n",
    "#### HYPER PARAMS\n",
    "LR = 0.0005         # learning rate\n",
    "N_TEST_IMG = 5\n",
    "\n",
    "class Decoder_1L_6D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder_1L_6D, self).__init__()\n",
    "        ###########################\n",
    "        #What is this used for?\n",
    "        #self.map = {}\n",
    "        ###########################\n",
    "        self.fc4 = nn.Linear(6, 784)\n",
    "\n",
    "        \n",
    "    def decode(self, z):\n",
    "        out=self.fc4(z)\n",
    "        return torch.sigmoid(out)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        encoded = x\n",
    "        #decoded= x\n",
    "        decoded = self.decode(encoded)\n",
    "        return encoded, decoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "tvehBzfvx9PC"
   },
   "source": [
    "### Decoder 2L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "q4d-M9dAx9PD"
   },
   "outputs": [],
   "source": [
    "#############################################################################################################\n",
    "###\n",
    "# PYTORCH DOCUMENTATION EXAMPLE\n",
    "# TUTORIAL USED: #https://github.com/MorvanZhou/PyTorch-Tutorial/blob/master/tutorial-contents/404_autoencoder.py\n",
    "###\n",
    "#### HYPER PARAMS\n",
    "LR = 0.0005         # learning rate\n",
    "N_TEST_IMG = 5\n",
    "\n",
    "class Decoder_2L_6D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder_2L_6D, self).__init__()\n",
    "        ###########################\n",
    "        #What is this used for?\n",
    "        #self.map = {}\n",
    "        ###########################\n",
    "        self.fc4 = nn.Linear(6, 100)\n",
    "        self.sig = nn.Sigmoid()\n",
    "        self.fc5 = nn.Linear(100, 784)\n",
    "\n",
    "        \n",
    "    def decode(self, z):\n",
    "        out=self.fc4(z)\n",
    "        out2=self.sig(out)\n",
    "        out3=self.fc5(out2)\n",
    "        out4=self.sig(out3)\n",
    "        return out4\n",
    "    \n",
    "    def forward(self, x):\n",
    "        encoded = x\n",
    "        #decoded= x\n",
    "        decoded = self.decode(encoded)\n",
    "        return encoded, decoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "sVR171Kpx9PH"
   },
   "source": [
    "### Decoder 3L6D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "aOm5gQl5x9PJ"
   },
   "outputs": [],
   "source": [
    "###\n",
    "# PYTORCH DOCUMENTATION EXAMPLE\n",
    "# TUTORIAL USED: #https://github.com/MorvanZhou/PyTorch-Tutorial/blob/master/tutorial-contents/404_autoencoder.py\n",
    "###\n",
    "#### HYPER PARAMS\n",
    "LR = 0.0005         # learning rate\n",
    "N_TEST_IMG = 5\n",
    "\n",
    "class Decoder_3L_6D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder_3L_6D, self).__init__()\n",
    "        ###########################\n",
    "        #What is this used for?\n",
    "        #self.map = {}\n",
    "        ###########################\n",
    "        self.fc4 = nn.Linear(6, 100)\n",
    "        self.sig = nn.Sigmoid()\n",
    "        self.fc5 = nn.Linear(100, 200)\n",
    "        self.fc6 = nn.Linear(200, 784)\n",
    "\n",
    "        \n",
    "    def decode(self, z):\n",
    "        out=self.fc4(z)\n",
    "        out2=self.sig(out)\n",
    "        out3=self.fc5(out2)\n",
    "        out4=self.sig(out3)\n",
    "        out5=self.fc6(out4)\n",
    "        out6=self.sig(out5)\n",
    "        return out6\n",
    "    \n",
    "    def forward(self, x):\n",
    "        encoded = x\n",
    "        #decoded= x\n",
    "        decoded = self.decode(encoded)\n",
    "        return encoded, decoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "5_hNAaICx9PO"
   },
   "source": [
    "### Decoder 4L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "v1SPWh0rx9PP"
   },
   "outputs": [],
   "source": [
    "#############################################################################################################\n",
    "###\n",
    "# PYTORCH DOCUMENTATION EXAMPLE\n",
    "# TUTORIAL USED: #https://github.com/MorvanZhou/PyTorch-Tutorial/blob/master/tutorial-contents/404_autoencoder.py\n",
    "###\n",
    "#### HYPER PARAMS\n",
    "LR = 0.0005         # learning rate\n",
    "N_TEST_IMG = 5\n",
    "\n",
    "class Decoder_4L_6D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder_4L_6D, self).__init__()\n",
    "        ###########################\n",
    "        #What is this used for?\n",
    "        #self.map = {}\n",
    "        ###########################\n",
    "        self.fc4 = nn.Linear(6, 100)\n",
    "        self.sig = nn.Sigmoid()\n",
    "        self.fc5 = nn.Linear(100,200)\n",
    "        self.fc6 = nn.Linear(200, 300)\n",
    "        self.fc7 = nn.Linear(300, 784)\n",
    "\n",
    "        \n",
    "    def decode(self, z):\n",
    "        out=self.fc4(z)\n",
    "        out2=self.sig(out)\n",
    "        out3=self.fc5(out2)\n",
    "        out4=self.sig(out3)\n",
    "        out5=self.fc6(out4)\n",
    "        out6=self.sig(out5)\n",
    "        out7=self.fc7(out6)\n",
    "        out8=self.sig(out7)\n",
    "        return out8\n",
    "    \n",
    "    def forward(self, x):\n",
    "        encoded = x\n",
    "        #decoded= x\n",
    "        decoded = self.decode(encoded)\n",
    "        return encoded, decoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "LkGnN3bqx9PV"
   },
   "source": [
    "### AE_1L6D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "pS4-73h5x9PW"
   },
   "outputs": [],
   "source": [
    "#############################################################################################################\n",
    "###\n",
    "# PYTORCH DOCUMENTATION EXAMPLE\n",
    "# TUTORIAL USED: #https://github.com/MorvanZhou/PyTorch-Tutorial/blob/master/tutorial-contents/404_autoencoder.py\n",
    "###\n",
    "#### HYPER PARAMS\n",
    "LR = 0.0005         # learning rate\n",
    "\n",
    "class AE_1L6D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AE_1L6D, self).__init__()\n",
    "        ###########################\n",
    "        #What is this used for?\n",
    "        #self.map = {}\n",
    "        ###########################\n",
    "        self.fw4 = nn.Linear(784, 6)\n",
    "        self.bc4 = nn.Linear(6, 784)\n",
    "        \n",
    "    def encode(self, z):\n",
    "        enc=self.fw4(z)\n",
    "        return torch.sigmoid(enc)\n",
    "        \n",
    "    \n",
    "    def decode(self, z):\n",
    "        out=self.bc4(z)\n",
    "        return torch.sigmoid(out)\n",
    "    \n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encode(x)\n",
    "        decoded = self.decode(encoded)\n",
    "        return encoded, decoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "A76FL3pox9PZ"
   },
   "source": [
    "### AE_2L6d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "8ph6rUpKx9PZ"
   },
   "outputs": [],
   "source": [
    "#############################################################################################################\n",
    "###\n",
    "# PYTORCH DOCUMENTATION EXAMPLE\n",
    "# TUTORIAL USED: #https://github.com/MorvanZhou/PyTorch-Tutorial/blob/master/tutorial-contents/404_autoencoder.py\n",
    "###\n",
    "#### HYPER PARAMS\n",
    "LR = 0.0005         # learning rate\n",
    "\n",
    "class AE_2L6D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AE_2L6D, self).__init__()\n",
    "        ###########################\n",
    "        #What is this used for?\n",
    "        #self.map = {}\n",
    "        ###########################\n",
    "        self.bc4 = nn.Linear(6, 100)\n",
    "        self.sig = nn.Sigmoid()\n",
    "        self.bc5 = nn.Linear(100, 784)\n",
    "        self.fw4 = nn.Linear(784, 100)\n",
    "        self.fw5 = nn.Linear(100, 6)\n",
    "        \n",
    "    def encode(self, z):\n",
    "        enc=self.fw4(z)\n",
    "        enc2=self.sig(enc)\n",
    "        enc3= self.fw5(enc2)\n",
    "        enc4=self.sig(enc3)   \n",
    "        return enc4\n",
    "        \n",
    "    \n",
    "    def decode(self, z):\n",
    "        out=self.bc4(z)\n",
    "        out2=self.sig(out)\n",
    "        out3=self.bc5(out2)\n",
    "        out4=self.sig(out3)\n",
    "        return out4\n",
    "    \n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encode(x)\n",
    "        decoded = self.decode(encoded)\n",
    "        return encoded, decoded\n",
    "### INITALIZE MODEL PARAMS\n",
    "model_AE2 =  AE_2L2D()\n",
    "optimizer = torch.optim.Adam(model_AE2.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "Q90Aboxrx9Pe"
   },
   "source": [
    "### 3L6D AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "_o9gDGJ7x9Pf"
   },
   "outputs": [],
   "source": [
    "#############################################################################################################\n",
    "###\n",
    "# PYTORCH DOCUMENTATION EXAMPLE\n",
    "# TUTORIAL USED: #https://github.com/MorvanZhou/PyTorch-Tutorial/blob/master/tutorial-contents/404_autoencoder.py\n",
    "###\n",
    "#### HYPER PARAMS\n",
    "LR = 0.0005         # learning rate\n",
    "\n",
    "class AE_3L6D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AE_3L6D, self).__init__()\n",
    "        ###########################\n",
    "        #What is this used for?\n",
    "        #self.map = {}\n",
    "        ###########################\n",
    "        self.bc4 = nn.Linear(6, 100)\n",
    "        self.sig = nn.Sigmoid()\n",
    "        self.bc5 = nn.Linear(100, 200)\n",
    "        self.bc6 = nn.Linear(200, 784)\n",
    "        self.fw4 = nn.Linear(784, 200)\n",
    "        self.fw5 = nn.Linear(200, 100)\n",
    "        self.fw6 = nn.Linear(100, 6)\n",
    "        \n",
    "    def encode(self, z):\n",
    "        enc=self.fw4(z)\n",
    "        enc2=self.sig(enc)\n",
    "        enc3= self.fw5(enc2)\n",
    "        enc4=self.sig(enc3)   \n",
    "        enc5=self.fw6(enc4)   \n",
    "        enc6=self.sig(enc5)   \n",
    "        return enc6\n",
    "        \n",
    "    \n",
    "    def decode(self, z):\n",
    "        out=self.bc4(z)\n",
    "        out2=self.sig(out)\n",
    "        out3=self.bc5(out2)\n",
    "        out4=self.sig(out3)\n",
    "        out5=self.bc6(out4)\n",
    "        out6=self.sig(out5)\n",
    "        return out6\n",
    "    \n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encode(x)\n",
    "        decoded = self.decode(encoded)\n",
    "        return encoded, decoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "uIRRJemtx9Pi"
   },
   "source": [
    "### AE 4L6D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "wg9rVKFfx9Pj"
   },
   "outputs": [],
   "source": [
    "#############################################################################################################\n",
    "###\n",
    "# PYTORCH DOCUMENTATION EXAMPLE\n",
    "# TUTORIAL USED: #https://github.com/MorvanZhou/PyTorch-Tutorial/blob/master/tutorial-contents/404_autoencoder.py\n",
    "###\n",
    "#### HYPER PARAMS\n",
    "LR = 0.0005         # learning rate\n",
    "\n",
    "class AE_4L6D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AE_4L6D, self).__init__()\n",
    "        ###########################\n",
    "        #What is this used for?\n",
    "        #self.map = {}\n",
    "        ###########################\n",
    "        self.fw4 = nn.Linear(784, 300)\n",
    "        self.fw5 = nn.Linear(300, 200)\n",
    "        self.fw6 = nn.Linear(200, 100)\n",
    "        self.fw7 = nn.Linear(100, 6)\n",
    "        self.sig = nn.Sigmoid()\n",
    "        self.bc4 = nn.Linear(6, 100)        \n",
    "        self.bc5 = nn.Linear(100, 200)\n",
    "        self.bc6 = nn.Linear(200, 300)\n",
    "        self.bc7 = nn.Linear(300, 784)\n",
    "\n",
    "\n",
    "    def encode(self, z):\n",
    "        enc=self.fw4(z)\n",
    "        enc2=self.sig(enc)\n",
    "        enc3= self.fw5(enc2)\n",
    "        enc4=self.sig(enc3) \n",
    "        enc5= self.fw6(enc4)\n",
    "        enc6=self.sig(enc5)  \n",
    "        enc7= self.fw7(enc6)\n",
    "        enc8=self.sig(enc7)  \n",
    "        return enc8\n",
    "        \n",
    "    \n",
    "    def decode(self, z):\n",
    "        out=self.bc4(z)\n",
    "        out2=self.sig(out)\n",
    "        out3= self.bc5(out2)\n",
    "        out4=self.sig(out3) \n",
    "        out5= self.bc6(out4)\n",
    "        out6=self.sig(out5)  \n",
    "        out7= self.bc7(out6)\n",
    "        out8=self.sig(out7)  \n",
    "        return out8\n",
    "    \n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encode(x)\n",
    "        decoded = self.decode(encoded)\n",
    "        return encoded, decoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "H2sZ5fVXx9Pm"
   },
   "source": [
    "## 50 D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "EmL23qLYx9Pm"
   },
   "source": [
    "### Decoder 1L50D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "code_folding": [],
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "Vt2z6gTex9Pn"
   },
   "outputs": [],
   "source": [
    "#############################################################################################################\n",
    "###\n",
    "# PYTORCH DOCUMENTATION EXAMPLE\n",
    "# TUTORIAL USED: #https://github.com/MorvanZhou/PyTorch-Tutorial/blob/master/tutorial-contents/404_autoencoder.py\n",
    "###\n",
    "#### HYPER PARAMS\n",
    "LR = 0.0005         # learning rate\n",
    "N_TEST_IMG = 5\n",
    "\n",
    "class Decoder_1L_50D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder_1L_50D, self).__init__()\n",
    "        ###########################\n",
    "        #What is this used for?\n",
    "        #self.map = {}\n",
    "        ###########################\n",
    "        self.fc4 = nn.Linear(50, 784)\n",
    "\n",
    "        \n",
    "    def decode(self, z):\n",
    "        out=self.fc4(z)\n",
    "        return torch.sigmoid(out)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        encoded = x\n",
    "        #decoded= x\n",
    "        decoded = self.decode(encoded)\n",
    "        return encoded, decoded\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "VVWmWLaXx9Pq"
   },
   "source": [
    "### Decoder 2L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "RPqxFv_Ex9Pr"
   },
   "outputs": [],
   "source": [
    "#############################################################################################################\n",
    "###\n",
    "# PYTORCH DOCUMENTATION EXAMPLE\n",
    "# TUTORIAL USED: #https://github.com/MorvanZhou/PyTorch-Tutorial/blob/master/tutorial-contents/404_autoencoder.py\n",
    "###\n",
    "#### HYPER PARAMS\n",
    "LR = 0.0005         # learning rate\n",
    "N_TEST_IMG = 5\n",
    "\n",
    "class Decoder_2L_50D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder_2L_50D, self).__init__()\n",
    "        ###########################\n",
    "        #What is this used for?\n",
    "        #self.map = {}\n",
    "        ###########################\n",
    "        self.fc4 = nn.Linear(50, 100)\n",
    "        self.sig = nn.Sigmoid()\n",
    "        self.fc5 = nn.Linear(100, 784)\n",
    "\n",
    "        \n",
    "    def decode(self, z):\n",
    "        out=self.fc4(z)\n",
    "        out2=self.sig(out)\n",
    "        out3=self.fc5(out2)\n",
    "        out4=self.sig(out3)\n",
    "        return out4\n",
    "    \n",
    "    def forward(self, x):\n",
    "        encoded = x\n",
    "        #decoded= x\n",
    "        decoded = self.decode(encoded)\n",
    "        return encoded, decoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "aPI_T2g6x9Pv"
   },
   "source": [
    "### Decoder 3L50D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "rfkBJmPJx9Pw"
   },
   "outputs": [],
   "source": [
    "###\n",
    "# PYTORCH DOCUMENTATION EXAMPLE\n",
    "# TUTORIAL USED: #https://github.com/MorvanZhou/PyTorch-Tutorial/blob/master/tutorial-contents/404_autoencoder.py\n",
    "###\n",
    "#### HYPER PARAMS\n",
    "LR = 0.0005         # learning rate\n",
    "N_TEST_IMG = 5\n",
    "\n",
    "class Decoder_3L_50D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder_3L_50D, self).__init__()\n",
    "        ###########################\n",
    "        #What is this used for?\n",
    "        #self.map = {}\n",
    "        ###########################\n",
    "        self.fc4 = nn.Linear(50, 100)\n",
    "        self.sig = nn.Sigmoid()\n",
    "        self.fc5 = nn.Linear(100, 200)\n",
    "        self.fc6 = nn.Linear(200, 784)\n",
    "\n",
    "        \n",
    "    def decode(self, z):\n",
    "        out=self.fc4(z)\n",
    "        out2=self.sig(out)\n",
    "        out3=self.fc5(out2)\n",
    "        out4=self.sig(out3)\n",
    "        out5=self.fc6(out4)\n",
    "        out6=self.sig(out5)\n",
    "        return out6\n",
    "    \n",
    "    def forward(self, x):\n",
    "        encoded = x\n",
    "        #decoded= x\n",
    "        decoded = self.decode(encoded)\n",
    "        return encoded, decoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "9Sbcok7Ax9P0"
   },
   "source": [
    "### Decoder 4L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "CC94XgpGx9P2"
   },
   "outputs": [],
   "source": [
    "#############################################################################################################\n",
    "###\n",
    "# PYTORCH DOCUMENTATION EXAMPLE\n",
    "# TUTORIAL USED: #https://github.com/MorvanZhou/PyTorch-Tutorial/blob/master/tutorial-contents/404_autoencoder.py\n",
    "###\n",
    "#### HYPER PARAMS\n",
    "LR = 0.0005         # learning rate\n",
    "N_TEST_IMG = 5\n",
    "\n",
    "class Decoder_4L_50D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder_4L_50D, self).__init__()\n",
    "        ###########################\n",
    "        #What is this used for?\n",
    "        #self.map = {}\n",
    "        ###########################\n",
    "        self.fc4 = nn.Linear(50, 100)\n",
    "        self.sig = nn.Sigmoid()\n",
    "        self.fc5 = nn.Linear(100,200)\n",
    "        self.fc6 = nn.Linear(200, 300)\n",
    "        self.fc7 = nn.Linear(300, 784)\n",
    "\n",
    "        \n",
    "    def decode(self, z):\n",
    "        out=self.fc4(z)\n",
    "        out2=self.sig(out)\n",
    "        out3=self.fc5(out2)\n",
    "        out4=self.sig(out3)\n",
    "        out5=self.fc6(out4)\n",
    "        out6=self.sig(out5)\n",
    "        out7=self.fc7(out6)\n",
    "        out8=self.sig(out7)\n",
    "        return out8\n",
    "    \n",
    "    def forward(self, x):\n",
    "        encoded = x\n",
    "        #decoded= x\n",
    "        decoded = self.decode(encoded)\n",
    "        return encoded, decoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "4R24KL9hx9P6"
   },
   "source": [
    "### 3L50D AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "NUGwJ1UDx9P7"
   },
   "outputs": [],
   "source": [
    "#############################################################################################################\n",
    "###\n",
    "# PYTORCH DOCUMENTATION EXAMPLE\n",
    "# TUTORIAL USED: #https://github.com/MorvanZhou/PyTorch-Tutorial/blob/master/tutorial-contents/404_autoencoder.py\n",
    "###\n",
    "#### HYPER PARAMS\n",
    "LR = 0.0005         # learning rate\n",
    "\n",
    "class AE_3L50D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AE_3L50D, self).__init__()\n",
    "        ###########################\n",
    "        #What is this used for?\n",
    "        #self.map = {}\n",
    "        ###########################\n",
    "        self.bc4 = nn.Linear(50, 100)\n",
    "        self.sig = nn.Sigmoid()\n",
    "        self.bc5 = nn.Linear(100, 200)\n",
    "        self.bc6 = nn.Linear(200, 784)\n",
    "        self.fw4 = nn.Linear(784, 200)\n",
    "        self.fw5 = nn.Linear(200, 100)\n",
    "        self.fw6 = nn.Linear(100, 50)\n",
    "        \n",
    "    def encode(self, z):\n",
    "        enc=self.fw4(z)\n",
    "        enc2=self.sig(enc)\n",
    "        enc3= self.fw5(enc2)\n",
    "        enc4=self.sig(enc3)   \n",
    "        enc5=self.fw6(enc4)   \n",
    "        enc6=self.sig(enc5)   \n",
    "        return enc6\n",
    "        \n",
    "    \n",
    "    def decode(self, z):\n",
    "        out=self.bc4(z)\n",
    "        out2=self.sig(out)\n",
    "        out3=self.bc5(out2)\n",
    "        out4=self.sig(out3)\n",
    "        out5=self.bc6(out4)\n",
    "        out6=self.sig(out5)\n",
    "        return out6\n",
    "    \n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encode(x)\n",
    "        decoded = self.decode(encoded)\n",
    "        return encoded, decoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "xSJJmhaLx9P-"
   },
   "source": [
    "### AE_1L50D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "ZqjOVHeMx9P_"
   },
   "outputs": [],
   "source": [
    "#############################################################################################################\n",
    "###\n",
    "# PYTORCH DOCUMENTATION EXAMPLE\n",
    "# TUTORIAL USED: #https://github.com/MorvanZhou/PyTorch-Tutorial/blob/master/tutorial-contents/404_autoencoder.py\n",
    "###\n",
    "#### HYPER PARAMS\n",
    "LR = 0.0005         # learning rate\n",
    "\n",
    "class AE_1L50D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AE_1L50D, self).__init__()\n",
    "        ###########################\n",
    "        #What is this used for?\n",
    "        #self.map = {}\n",
    "        ###########################\n",
    "        self.fw4 = nn.Linear(784, 50)\n",
    "        self.bc4 = nn.Linear(50, 784)\n",
    "        \n",
    "    def encode(self, z):\n",
    "        enc=self.fw4(z)\n",
    "        return torch.sigmoid(enc)\n",
    "        \n",
    "    \n",
    "    def decode(self, z):\n",
    "        out=self.bc4(z)\n",
    "        return torch.sigmoid(out)\n",
    "    \n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encode(x)\n",
    "        decoded = self.decode(encoded)\n",
    "        return encoded, decoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "qh_unlmRx9QD"
   },
   "source": [
    "### AE_2L50D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "3BPfldLbx9QE"
   },
   "outputs": [],
   "source": [
    "#############################################################################################################\n",
    "###\n",
    "# PYTORCH DOCUMENTATION EXAMPLE\n",
    "# TUTORIAL USED: #https://github.com/MorvanZhou/PyTorch-Tutorial/blob/master/tutorial-contents/404_autoencoder.py\n",
    "###\n",
    "#### HYPER PARAMS\n",
    "LR = 0.0005         # learning rate\n",
    "\n",
    "class AE_2L50D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AE_2L50D, self).__init__()\n",
    "        ###########################\n",
    "        #What is this used for?\n",
    "        #self.map = {}\n",
    "        ###########################\n",
    "        self.bc4 = nn.Linear(50, 100)\n",
    "        self.sig = nn.Sigmoid()\n",
    "        self.bc5 = nn.Linear(100, 784)\n",
    "        self.fw4 = nn.Linear(784, 100)\n",
    "        self.fw5 = nn.Linear(100, 50)\n",
    "        \n",
    "    def encode(self, z):\n",
    "        enc=self.fw4(z)\n",
    "        enc2=self.sig(enc)\n",
    "        enc3= self.fw5(enc2)\n",
    "        enc4=self.sig(enc3)   \n",
    "        return enc4\n",
    "        \n",
    "    \n",
    "    def decode(self, z):\n",
    "        out=self.bc4(z)\n",
    "        out2=self.sig(out)\n",
    "        out3=self.bc5(out2)\n",
    "        out4=self.sig(out3)\n",
    "        return out4\n",
    "    \n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encode(x)\n",
    "        decoded = self.decode(encoded)\n",
    "        return encoded, decoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "S4t3zRSyx9QH"
   },
   "source": [
    "### AE 4L50D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "aPQVF8Sex9QJ"
   },
   "outputs": [],
   "source": [
    "#############################################################################################################\n",
    "###\n",
    "# PYTORCH DOCUMENTATION EXAMPLE\n",
    "# TUTORIAL USED: #https://github.com/MorvanZhou/PyTorch-Tutorial/blob/master/tutorial-contents/404_autoencoder.py\n",
    "###\n",
    "#### HYPER PARAMS\n",
    "LR = 0.0005         # learning rate\n",
    "\n",
    "class AE_4L50D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AE_4L50D, self).__init__()\n",
    "        ###########################\n",
    "        #What is this used for?\n",
    "        #self.map = {}\n",
    "        ###########################\n",
    "        self.fw4 = nn.Linear(784, 300)\n",
    "        self.fw5 = nn.Linear(300, 200)\n",
    "        self.fw6 = nn.Linear(200, 100)\n",
    "        self.fw7 = nn.Linear(100, 50)\n",
    "        self.sig = nn.Sigmoid()\n",
    "        self.bc4 = nn.Linear(50, 100)        \n",
    "        self.bc5 = nn.Linear(100, 200)\n",
    "        self.bc6 = nn.Linear(200, 300)\n",
    "        self.bc7 = nn.Linear(300, 784)\n",
    "\n",
    "\n",
    "    def encode(self, z):\n",
    "        enc=self.fw4(z)\n",
    "        enc2=self.sig(enc)\n",
    "        enc3= self.fw5(enc2)\n",
    "        enc4=self.sig(enc3) \n",
    "        enc5= self.fw6(enc4)\n",
    "        enc6=self.sig(enc5)  \n",
    "        enc7= self.fw7(enc6)\n",
    "        enc8=self.sig(enc7)  \n",
    "        return enc8\n",
    "        \n",
    "    \n",
    "    def decode(self, z):\n",
    "        out=self.bc4(z)\n",
    "        out2=self.sig(out)\n",
    "        out3= self.bc5(out2)\n",
    "        out4=self.sig(out3) \n",
    "        out5= self.bc6(out4)\n",
    "        out6=self.sig(out5)  \n",
    "        out7= self.bc7(out6)\n",
    "        out8=self.sig(out7)  \n",
    "        return out8\n",
    "    \n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encode(x)\n",
    "        decoded = self.decode(encoded)\n",
    "        return encoded, decoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "heading_collapsed": true,
    "id": "25l-ifLxx9QM"
   },
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "26J0SafNx9QN"
   },
   "outputs": [],
   "source": [
    "def loss_function(recon_x, x):\n",
    "    BCE = F.binary_cross_entropy(recon_x, x, reduction='sum')\n",
    "    return(BCE)\n",
    "def decode_loader(data, batch_size):\n",
    "    perm = torch.randperm(data.size(0))\n",
    "    idx = perm[:batch_size]\n",
    "    batch=data[idx]\n",
    "    return(batch)\n",
    "def export_tensor(out_tensor,filename):\n",
    "    arr = out_tensor.data.cpu().numpy()\n",
    "    # write CSV\n",
    "    np.savetxt(filename, arr)\n",
    "def import_tensor(filename):\n",
    "    from numpy import genfromtxt\n",
    "    test = np.genfromtxt(filename)\n",
    "    import_tensor=torch.tensor(test, dtype=torch.float)\n",
    "    return(import_tensor)\n",
    "def import_saved_output(filenames,loss_filename):\n",
    "    imp_data=[]\n",
    "    for i in range(0,len(filenames)):\n",
    "        out_file='output/'+filenames[i]+'.csv'\n",
    "        test=import_tensor(out_file)\n",
    "        imp_data.append(test)\n",
    "    test_lossvec = np.genfromtxt(loss_filename)\n",
    "    return(imp_data, test_lossvec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "heading_collapsed": true,
    "id": "WOHk-qVKx9QQ"
   },
   "source": [
    "# Data Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "SPCY5lTwx9QR"
   },
   "source": [
    "## Pull Indices and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "nSOUZVbtx9QR"
   },
   "outputs": [],
   "source": [
    "def get_images(img_return_cnt,labels_raw, data_raw):\n",
    "    found=False\n",
    "    img_agg_cnt=np.zeros(10)\n",
    "    img_return_cnt=np.array(img_return_cnt)\n",
    "    i=0\n",
    "    labels=[]\n",
    "    indices=[]\n",
    "    while found==False and 70000>i:\n",
    "        target=labels_raw[i]\n",
    "        index=int(labels_raw[i].data)\n",
    "        if np.dot(np.subtract(img_agg_cnt, img_return_cnt),np.ones(10))==0:\n",
    "            found=True\n",
    "        else:\n",
    "            if img_agg_cnt[index] < img_return_cnt[index]:\n",
    "                img_agg_cnt[index]+=1\n",
    "                indices.append(i)\n",
    "        i+=1\n",
    "    return(indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "7esglvhmx9QU"
   },
   "source": [
    "## Gen Random Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "osBwbnsix9QV"
   },
   "outputs": [],
   "source": [
    "def gen_rand_data(img_return_cnt,labels_raw, data_raw,Rdim):\n",
    "    #num_img_type= scalar= equal to the number of image categories\n",
    "    #img_return_cnt = array = index of array is the image type and value is sample size for image type\n",
    "    #example_data = data loader data in form: batch_idx, (example_data, example_targets) \n",
    "    #max_i= data size\n",
    "    #Rdim= vector dimension for rand generation\n",
    "    #img_return_cnt = array = index of array is the image type and value is sample size for image type\n",
    "    found=False\n",
    "    img_agg_cnt=np.zeros(10)\n",
    "    img_return_cnt=np.array(img_return_cnt)\n",
    "    i=0\n",
    "    first=True\n",
    "    labels=[]\n",
    "    indices=[]\n",
    "    while found==False and 70000>i:\n",
    "        target=labels_raw[i]\n",
    "        index=int(labels_raw[i].data)\n",
    "        if np.dot(np.subtract(img_agg_cnt, img_return_cnt),np.ones(10))==0:\n",
    "            found=True\n",
    "        else:\n",
    "            if img_agg_cnt[index] < img_return_cnt[index]:\n",
    "                labels.append(target.item())\n",
    "                datum=data_raw[i].view(-1,28*28)\n",
    "                img_agg_cnt[index]+=1\n",
    "                indices.append(i)\n",
    "                if first==True:\n",
    "                    x_tensor=datum\n",
    "                    randEnc_tensor=torch.rand(1, Rdim).cuda()\n",
    "                    first=False \n",
    "                else:\n",
    "                    omega=torch.rand(1, Rdim).cuda()\n",
    "                    x_tensor=torch.cat((x_tensor,datum),0)\n",
    "                    randEnc_tensor=torch.cat((randEnc_tensor,omega),0)\n",
    "        i+=1\n",
    "    data = rgenData(randEnc_tensor, x_tensor)\n",
    "    return(data, labels, indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "JTJFjv1rx9QZ"
   },
   "source": [
    "## Create RandEmbedding with Image Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "UQpB3bvNx9Qa"
   },
   "outputs": [],
   "source": [
    "def get_randenc_byindex(indices, labels_raw, data_raw,Rdim):\n",
    "    #num_img_type= scalar= equal to the number of image categories\n",
    "    #img_return_cnt = array = index of array is the image type and value is sample size for image type\n",
    "    #example_data = data loader data in form: batch_idx, (example_data, example_targets) \n",
    "    #max_i= data size\n",
    "    #Rdim= vector dimension for rand generation\n",
    "    #img_return_cnt = array = index of array is the image type and value is sample size for image type\n",
    "    i=0\n",
    "    cnt=len(indices)\n",
    "    labels=[]\n",
    "    datum=data_raw[indices[0]].view(-1,28*28)\n",
    "    x_tensor=datum.cuda()\n",
    "    randEnc_tensor=torch.rand(1, Rdim).cuda()\n",
    "    labels.append(labels_raw[0])\n",
    "    for i in range(1,len(indices)):\n",
    "        index=indices[i]\n",
    "        labels.append(labels_raw[index])\n",
    "        datum=data_raw[index].view(-1,28*28)\n",
    "        omega=torch.rand(1, Rdim).cuda()\n",
    "        x_tensor=torch.cat((x_tensor,datum),0)\n",
    "        randEnc_tensor=torch.cat((randEnc_tensor,omega),0)\n",
    "    data = rgenData(randEnc_tensor, x_tensor)\n",
    "    return(data, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "B5LToT-Gx9Qf"
   },
   "source": [
    "## Gen Dataset Given Image Index & Array of Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "2vgwyRmTx9Qo"
   },
   "outputs": [],
   "source": [
    "def get_enc_img(indices,labels_raw, data_raw,embedding):\n",
    "    #num_img_type= scalar= equal to the number of image categories\n",
    "    #img_return_cnt = array = index of array is the image type and value is sample size for image type\n",
    "    #example_data = data loader data in form: batch_idx, (example_data, example_targets) \n",
    "    #max_i= data size\n",
    "    #Rdim= vector dimension for rand generation\n",
    "    #img_return_cnt = array = index of array is the image type and value is sample size for image type\n",
    "    i=0\n",
    "    cnt=len(indices)\n",
    "    labels=[]\n",
    "    datum=data_raw[indices[0]].view(-1,28*28)\n",
    "    x_tensor=datum\n",
    "    randEnc_tensor=torch.tensor(embedding[0], dtype=torch.float)\n",
    "    labels.append(labels_raw[0])\n",
    "    for i in range(1,len(indices)):\n",
    "        index=indices[i]\n",
    "        labels.append(labels_raw[index])\n",
    "        datum=data_raw[index].view(-1,28*28)\n",
    "        omega=torch.tensor(embedding[i], dtype=torch.float)\n",
    "        x_tensor=torch.cat((x_tensor,datum),0)\n",
    "        randEnc_tensor=torch.cat((randEnc_tensor,omega),0)\n",
    "    data = rgenData(randEnc_tensor, x_tensor)\n",
    "    return(data, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZMsQJaJWx9Qr"
   },
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "935_g5cXx9Qs"
   },
   "source": [
    "## Train Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pi-CJxPWx9Qt"
   },
   "outputs": [],
   "source": [
    "def train_decoder(epoch, data, model, optimizer,size,log_interval=10):\n",
    "    train_loss = 0\n",
    "    optimizer.zero_grad()\n",
    "    lossvec=[]\n",
    "    lossvec_cnt=[]\n",
    "    cnt=0\n",
    "    for i in range(1, epoch):\n",
    "        train_loss = 0\n",
    "        if i%10000==0:\n",
    "            print(i)\n",
    "        for j in range(0,size):\n",
    "            x=data.x[j]\n",
    "            randEnc=data.randEnc[j]\n",
    "            cnt+=1\n",
    "            encoded, decoded = model.forward(randEnc)\n",
    "            loss = loss_function(decoded, x)\n",
    "            loss.backward()\n",
    "            train_loss += loss.item()\n",
    "            optimizer.step()\n",
    "            '''\n",
    "            if batch_idx % log_interval == 0:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    i, batch_idx * len(x), len(train_loader.dataset),\n",
    "                    100. * batch_idx / len(train_loader),\n",
    "                    loss.item() / len(x)))\n",
    "            '''\n",
    "        lossvec.append(train_loss / size)\n",
    "        lossvec_cnt.append(i)\n",
    "        \n",
    "    return (lossvec, lossvec_cnt, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IPg07JmHx9Qw"
   },
   "source": [
    "## Train AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qzUxa_xIx9Qx"
   },
   "outputs": [],
   "source": [
    "def train_AE(epoch, data, model, optimizer,size,log_interval=10):\n",
    "    train_loss = 0\n",
    "    optimizer.zero_grad()\n",
    "    lossvec=[]\n",
    "    lossvec_cnt=[]\n",
    "    cnt=0\n",
    "    for i in range(1, epoch):\n",
    "        train_loss = 0\n",
    "        if i%10000==0:\n",
    "            print(i)\n",
    "        for j in range(0,size):\n",
    "            x=data.x[j]\n",
    "            cnt+=1\n",
    "            encoded, decoded = model.forward(x)\n",
    "            loss = loss_function(decoded, x)\n",
    "            loss.backward()\n",
    "            train_loss += loss.item()\n",
    "            optimizer.step()\n",
    "            '''\n",
    "            if batch_idx % log_interval == 0:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    i, batch_idx * len(x), len(train_loader.dataset),\n",
    "                    100. * batch_idx / len(train_loader),\n",
    "                    loss.item() / len(x)))\n",
    "            '''\n",
    "        lossvec.append(train_loss / size)\n",
    "        lossvec_cnt.append(i)\n",
    "        \n",
    "    return (lossvec, lossvec_cnt, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "heading_collapsed": true,
    "id": "xlUS2iWFx9Q2"
   },
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "KIfVyAZMx9Q3"
   },
   "outputs": [],
   "source": [
    "def x_xd_plot_compare(data,model,instances,ae=False): \n",
    "    rows=instances\n",
    "    cols=2\n",
    "    tot=int(instances)*cols\n",
    "    fig = plt.figure(figsize=(rows, rows))\n",
    "    plt.tight_layout() \n",
    "    # plot with various axes scales\n",
    "    loc=0\n",
    "    fig.subplots_adjust(hspace=.5)\n",
    "    case=0\n",
    "    while case<(rows):\n",
    "        # linear\n",
    "        loc+=1\n",
    "        tensor=data[case][1].view(28,28)\n",
    "        if ae==False:\n",
    "            tensor_d=model.decode(data[case][0])\n",
    "            encoded=data[case][0]\n",
    "        else:\n",
    "            encoded, tensor_d=model.forward(data[case][1])\n",
    "        Rdim=encoded.shape\n",
    "        Rdim=Rdim[0]\n",
    "        tensor_d_plt=tensor_d.view(28,28)\n",
    "        plt.subplot(rows, cols, loc).axis('off')\n",
    "        plt.imshow(tensor.cpu().detach().numpy(),cmap='gray')\n",
    "        plt.title(str(case))\n",
    "\n",
    "\n",
    "        loc+=1\n",
    "        # log\n",
    "        plt.subplot(rows, cols, loc).axis('off')\n",
    "        plt.imshow(tensor_d_plt.cpu().detach().numpy(),cmap='gray')\n",
    "        plt.title(str(case))\n",
    "\n",
    "\n",
    "        if case==0:\n",
    "            exp_tensor=data[case][1]\n",
    "            exp_tensor_d=tensor_d\n",
    "            exp_omega=encoded\n",
    "        else:\n",
    "            exp_tensor=torch.cat((exp_tensor,data[case][1]),0)\n",
    "            exp_tensor_d=torch.cat((exp_tensor_d,tensor_d),0)\n",
    "            exp_omega=torch.cat((exp_omega, encoded),0)\n",
    "        case+=1\n",
    "\n",
    "    plt.show()\n",
    "    return(exp_tensor.view(instances,784),exp_tensor_d.view(instances,784),exp_omega.view(instances,Rdim))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "QWFrP0CWx9Q7"
   },
   "outputs": [],
   "source": [
    "def plot_compare(x, x_d): \n",
    "    rows=len(x)\n",
    "    cols=2\n",
    "    fig = plt.figure(figsize=(rows, rows))\n",
    "    plt.tight_layout() \n",
    "    # plot with various axes scales\n",
    "    loc=0\n",
    "    fig.subplots_adjust(hspace=.5)\n",
    "    case=0\n",
    "    while case<(rows):\n",
    "        tensor=x[case].view(28,28)      \n",
    "        tensor_d=x_d[case].view(28,28)\n",
    "        ########################################\n",
    "        loc+=1\n",
    "        plt.subplot(rows, cols, loc).axis('off')\n",
    "        plt.imshow(tensor.detach().numpy(),cmap='gray')\n",
    "        plt.title(str(case))\n",
    "\n",
    "        loc+=1\n",
    "        # log\n",
    "        plt.subplot(rows, cols, loc).axis('off')\n",
    "        plt.imshow(tensor_d.detach().numpy(),cmap='gray')\n",
    "        plt.title(str(case))\n",
    "        case+=1\n",
    "    plt.show()\n",
    "    return()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gDyTBLHXx9Q-"
   },
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 29601,
     "status": "ok",
     "timestamp": 1555076541802,
     "user": {
      "displayName": "Claire Danaher",
      "photoUrl": "",
      "userId": "09987109089678159139"
     },
     "user_tz": 240
    },
    "id": "JmsX10M2x9Q-",
    "outputId": "58d56257-57bd-4599-8aa7-1a80fc989422"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zjLRlZxjx9RD"
   },
   "outputs": [],
   "source": [
    "exp_name=\"Decoder_LossUpdate_6D_\"\n",
    "path=\"output/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1C6mst6yx9RG"
   },
   "outputs": [],
   "source": [
    "#labelset, dataset=gen_mnist()\n",
    "EPOCH=100000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pirAk1acx9RI"
   },
   "source": [
    "## Import MNIST Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1590,
     "status": "ok",
     "timestamp": 1555077222195,
     "user": {
      "displayName": "Claire Danaher",
      "photoUrl": "",
      "userId": "09987109089678159139"
     },
     "user_tz": 240
    },
    "id": "5eyMKTZIx9RJ",
    "outputId": "a0d29b3d-3d67-4fd6-e5ad-8e9425b5178d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda found\n"
     ]
    }
   ],
   "source": [
    "print('cuda found')\n",
    "#print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gIW7xVaBx9RQ"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "import_file = np.genfromtxt('/content/gdrive/My Drive/mnist_labelset.txt')\n",
    "labelset=torch.tensor(import_file).cuda()\n",
    "#labelset=torch.tensor(import_file)\n",
    "pd_dataset=pd.read_csv(\"/content/gdrive/My Drive/mnist_dataset.csv\")\n",
    "np_dataset=pd_dataset.as_matrix()\n",
    "dataset_test=np_dataset.reshape(70000,28,28)\n",
    "dataset=torch.tensor(dataset_test,dtype=torch.float).cuda()\n",
    "#dataset=torch.tensor(dataset_test,dtype=torch.float\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 12754,
     "status": "ok",
     "timestamp": 1555077233402,
     "user": {
      "displayName": "Claire Danaher",
      "photoUrl": "",
      "userId": "09987109089678159139"
     },
     "user_tz": 240
    },
    "id": "iB3Px_nPx9RS",
    "outputId": "f45d5c3d-4ad3-4344-9e36-0f492f0c5e47"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import_file = np.genfromtxt(\\'mnist_labelset.txt\\')\\nlabelset=torch.tensor(import_file).cuda()\\n#labelset=torch.tensor(import_file)\\npd_dataset=pd.read_csv(\"mnist_dataset.csv\")\\nnp_dataset=pd_dataset.as_matrix()\\ndataset_test=np_dataset.reshape(70000,28,28)\\ndataset=torch.tensor(dataset_test,dtype=torch.float).cuda()\\n#dataset=torch.tensor(dataset_test,dtype=torch.float'"
      ]
     },
     "execution_count": 58,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import_file = np.genfromtxt('mnist_labelset.txt')\n",
    "labelset=torch.tensor(import_file).cuda()\n",
    "#labelset=torch.tensor(import_file)\n",
    "pd_dataset=pd.read_csv(\"mnist_dataset.csv\")\n",
    "np_dataset=pd_dataset.as_matrix()\n",
    "dataset_test=np_dataset.reshape(70000,28,28)\n",
    "dataset=torch.tensor(dataset_test,dtype=torch.float).cuda()\n",
    "#dataset=torch.tensor(dataset_test,dtype=torch.float"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VHJFEckfx9RY"
   },
   "source": [
    "### Ref code for pulling images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DjBQQ5eDx9RY"
   },
   "source": [
    "## Gen Data by Dime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 12741,
     "status": "ok",
     "timestamp": 1555077233405,
     "user": {
      "displayName": "Claire Danaher",
      "photoUrl": "",
      "userId": "09987109089678159139"
     },
     "user_tz": 240
    },
    "id": "kkLmY3vOx9RZ",
    "outputId": "5cb7b074-11b5-4300-b9eb-6f2b57de66fd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimg_return_cnt=np.zeros(10)\\nimg_return_cnt[0]=2\\nimg_return_cnt[1]=2\\nimg_return_cnt[2]=2\\nimg_return_cnt[3]=2\\nimg_return_cnt[4]=2\\nimg_return_cnt[5]=2\\nimg_return_cnt[6]=1\\nimg_return_cnt[7]=1\\nimg_return_cnt[8]=1\\nimg_return_cnt[9]=1\\nrdim=2\\nbatch_size=4\\n\\nindices=get_images(img_return_cnt,labelset, dataset)\\nind_shuffle=indices[:]\\nshuffle(ind_shuffle)\\nprint(ind_shuffle)\\ndata, labels=get_randenc_byindex(ind_shuffle, labelset, dataset,rdim)\\n'"
      ]
     },
     "execution_count": 59,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pull Rnadom Encodings for Certain Image Types\n",
    "'''\n",
    "img_return_cnt=np.zeros(10)\n",
    "img_return_cnt[0]=2\n",
    "img_return_cnt[1]=2\n",
    "img_return_cnt[2]=2\n",
    "img_return_cnt[3]=2\n",
    "img_return_cnt[4]=2\n",
    "img_return_cnt[5]=2\n",
    "img_return_cnt[6]=1\n",
    "img_return_cnt[7]=1\n",
    "img_return_cnt[8]=1\n",
    "img_return_cnt[9]=1\n",
    "rdim=2\n",
    "batch_size=4\n",
    "\n",
    "indices=get_images(img_return_cnt,labelset, dataset)\n",
    "ind_shuffle=indices[:]\n",
    "shuffle(ind_shuffle)\n",
    "print(ind_shuffle)\n",
    "data, labels=get_randenc_byindex(ind_shuffle, labelset, dataset,rdim)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XcaHk_bEx9Rc"
   },
   "outputs": [],
   "source": [
    "# Pull Random Encodings and Random Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v0nuAC5tx9Rf"
   },
   "outputs": [],
   "source": [
    "rdim=6\n",
    "batch_size=4\n",
    "ind_shuffle=[24755, 48200, 1, 18624, 0, 24754, 12666, 30596, 54051, 30597, 5924, 18623, 41935, 12665, 36017, 5923]\n",
    "data, labels=get_randenc_byindex(ind_shuffle, labelset, dataset,rdim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eG1MJmGm0gtK"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8589EqBj0gPX"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 12711,
     "status": "ok",
     "timestamp": 1555077233420,
     "user": {
      "displayName": "Claire Danaher",
      "photoUrl": "",
      "userId": "09987109089678159139"
     },
     "user_tz": 240
    },
    "id": "A_Fq1koXx9Rh",
    "outputId": "a9a649c8-69e7-47a6-fa1f-6debb80d8b54"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nembedding=np.matrix([[1, -1, 1, -1, 1, -1, 1, -1, 1, -1, 1, -1, 1, -1, 1, -1],\\n[1, 1, -1, -1, 1, 1, -1, -1, 1, 1, -1, -1, 1, 1, -1, -1],\\n[1, -1, -1, 1, 1, -1, -1, 1, 1, -1, -1, 1, 1, -1, -1, 1],\\n[1, -1, 1, -1, -1, 1, -1, 1, 1, -1, 1, -1, -1, 1, -1, 1],\\n[1, 1, -1, -1, 1, 1, -1, -1, -1, -1, 1, 1, -1, -1, 1, 1],\\n[1, -1, -1, -1,-1, 1, 1, -1, -1, 1, 1, -1, 1, -1, -1, 1]])\\nembedding=embedding.transpose()\\n\\nind_shuffle=indices[:]\\n\\ndata, labels=get_enc_img(ind_shuffle,labelset, dataset,embedding)\\n'"
      ]
     },
     "execution_count": 62,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pull Images to go with ETF\n",
    "'''\n",
    "embedding=np.matrix([[1, -1, 1, -1, 1, -1, 1, -1, 1, -1, 1, -1, 1, -1, 1, -1],\n",
    "[1, 1, -1, -1, 1, 1, -1, -1, 1, 1, -1, -1, 1, 1, -1, -1],\n",
    "[1, -1, -1, 1, 1, -1, -1, 1, 1, -1, -1, 1, 1, -1, -1, 1],\n",
    "[1, -1, 1, -1, -1, 1, -1, 1, 1, -1, 1, -1, -1, 1, -1, 1],\n",
    "[1, 1, -1, -1, 1, 1, -1, -1, -1, -1, 1, 1, -1, -1, 1, 1],\n",
    "[1, -1, -1, -1,-1, 1, 1, -1, -1, 1, 1, -1, 1, -1, -1, 1]])\n",
    "embedding=embedding.transpose()\n",
    "\n",
    "ind_shuffle=indices[:]\n",
    "\n",
    "data, labels=get_enc_img(ind_shuffle,labelset, dataset,embedding)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xaY5AsMEx9Rm"
   },
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J3dXeculx9Rm"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rOxwjbt8x9Rq"
   },
   "source": [
    "### Run Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 12694,
     "status": "ok",
     "timestamp": 1555077233426,
     "user": {
      "displayName": "Claire Danaher",
      "photoUrl": "",
      "userId": "09987109089678159139"
     },
     "user_tz": 240
    },
    "id": "6GTfLZ30x9Rq",
    "outputId": "2e1084ab-4a76-4324-af49-e7c89818c56a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded as cuda\n",
      "<generator object Module.parameters at 0x7f44f8bf5fc0>\n"
     ]
    }
   ],
   "source": [
    "expnum='1'\n",
    "model_in =   Decoder_1L_6D().cuda()\n",
    "#model_in =   AE_1L50D()\n",
    "print('model loaded as cuda')\n",
    "print(model_in.parameters())\n",
    "optimizer = torch.optim.Adam(model_in.parameters(), lr=LR)\n",
    "train_loss = 0\n",
    "optimizer.zero_grad()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "code_folding": [],
    "colab": {},
    "colab_type": "code",
    "id": "S4ElwkOCx9Rt",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "size=len(labels)\n",
    "start_time = time.time()\n",
    "lossvec, lossvec_cnt, model=train_decoder(EPOCH,data,model_in, optimizer,size) \n",
    "print('--- train mins %---')\n",
    "print((time.time() - start_time)/60)\n",
    "######################################\n",
    "\n",
    "###############################################################################################################################\n",
    "## UPDATE\n",
    "print(exp_name)\n",
    "tensor, tensor_d, omega=x_xd_plot_compare(data,model,size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tT7uzCwQx9Ry"
   },
   "outputs": [],
   "source": [
    "# Print model's state_dict\n",
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in model_in.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
    "\n",
    "# Print optimizer's state_dict\n",
    "print(\"Optimizer's state_dict:\")\n",
    "for var_name in optimizer.state_dict():\n",
    "    print(var_name, \"\\t\", optimizer.state_dict()[var_name])\n",
    "    \n",
    "PATH=path+exp_name+'exp'+expnum+'model.pt'\n",
    "torch.save(model_in.state_dict(), PATH)\n",
    "\n",
    "###############################################################################################################################\n",
    "## UPDATE\n",
    "print(exp_name)\n",
    "tensor, tensor_d, omega=x_xd_plot_compare(data,model,size,ae=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N_E4F4wrx9R0"
   },
   "outputs": [],
   "source": [
    "tensor_d_name=path+exp_name+'exp'+expnum+'_tensor_d'\n",
    "tensor_name=path+exp_name+'exp'+expnum+'_tensor'\n",
    "omega_name=path+exp_name+'exp'+expnum+'_omega'\n",
    "loss_filename=path+exp_name+'exp'+expnum+'_lossvec.csv'\n",
    "labels_filename=path+exp_name+'exp'+expnum+'_labels_test.csv'\n",
    "\n",
    "filenames=[tensor_name, tensor_d_name, omega_name]\n",
    "data_out=[]\n",
    "data_out.append(tensor)\n",
    "data_out.append(tensor_d)\n",
    "data_out.append(omega)\n",
    "\n",
    "for i in range(0,len(filenames)):\n",
    "    out_file=filenames[i]+'.csv'\n",
    "    export_tensor(data_out[i],out_file)\n",
    "np.savetxt(loss_filename, lossvec)\n",
    "np.savetxt(labels_filename, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aeRceE5Mx9R3"
   },
   "source": [
    "### Run Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p92yVAXdx9R4"
   },
   "outputs": [],
   "source": [
    "expnum='2'\n",
    "model_in =   Decoder_2L_6D().cuda()\n",
    "#model_in =   AE_1L50D()\n",
    "print('model loaded as cuda')\n",
    "print(model_in.parameters())\n",
    "optimizer = torch.optim.Adam(model_in.parameters(), lr=LR)\n",
    "train_loss = 0\n",
    "optimizer.zero_grad()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "code_folding": [],
    "colab": {},
    "colab_type": "code",
    "id": "iek10r_fx9R6",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "size=len(labels)\n",
    "start_time = time.time()\n",
    "lossvec, lossvec_cnt, model=train_decoder(EPOCH,data,model_in, optimizer,size) \n",
    "print('--- train mins %---')\n",
    "print((time.time() - start_time)/60)\n",
    "######################################\n",
    "\n",
    "###############################################################################################################################\n",
    "## UPDATE\n",
    "print(exp_name)\n",
    "tensor, tensor_d, omega=x_xd_plot_compare(data,model,size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jKCr3y9Qx9R9"
   },
   "outputs": [],
   "source": [
    "# Print model's state_dict\n",
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in model_in.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
    "\n",
    "# Print optimizer's state_dict\n",
    "print(\"Optimizer's state_dict:\")\n",
    "for var_name in optimizer.state_dict():\n",
    "    print(var_name, \"\\t\", optimizer.state_dict()[var_name])\n",
    "    \n",
    "PATH=path+exp_name+'exp'+expnum+'model.pt'\n",
    "torch.save(model_in.state_dict(), PATH)\n",
    "\n",
    "###############################################################################################################################\n",
    "## UPDATE\n",
    "print(exp_name)\n",
    "tensor, tensor_d, omega=x_xd_plot_compare(data,model,size,ae=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CuPRSdBJx9R_"
   },
   "outputs": [],
   "source": [
    "tensor_d_name=path+exp_name+'exp'+expnum+'_tensor_d'\n",
    "tensor_name=path+exp_name+'exp'+expnum+'_tensor'\n",
    "omega_name=path+exp_name+'exp'+expnum+'_omega'\n",
    "loss_filename=path+exp_name+'exp'+expnum+'_lossvec.csv'\n",
    "labels_filename=path+exp_name+'exp'+expnum+'_labels_test.csv'\n",
    "\n",
    "filenames=[tensor_name, tensor_d_name, omega_name]\n",
    "data_out=[]\n",
    "data_out.append(tensor)\n",
    "data_out.append(tensor_d)\n",
    "data_out.append(omega)\n",
    "\n",
    "for i in range(0,len(filenames)):\n",
    "    out_file=filenames[i]+'.csv'\n",
    "    export_tensor(data_out[i],out_file)\n",
    "np.savetxt(loss_filename, lossvec)\n",
    "np.savetxt(labels_filename, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yeYjwURox9SC"
   },
   "source": [
    "### Run Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bzsYce8mx9SE"
   },
   "outputs": [],
   "source": [
    "expnum='3'\n",
    "model_in =   Decoder_3L_6D().cuda()\n",
    "#model_in =   AE_1L50D()\n",
    "print('model loaded as cuda')\n",
    "print(model_in.parameters())\n",
    "optimizer = torch.optim.Adam(model_in.parameters(), lr=LR)\n",
    "train_loss = 0\n",
    "optimizer.zero_grad()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "code_folding": [],
    "colab": {},
    "colab_type": "code",
    "id": "PzwpPsC0x9SH",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "size=len(labels)\n",
    "start_time = time.time()\n",
    "lossvec, lossvec_cnt, model=train_decoder(EPOCH,data,model_in, optimizer,size) \n",
    "print('--- train mins %---')\n",
    "print((time.time() - start_time)/60)\n",
    "######################################\n",
    "\n",
    "###############################################################################################################################\n",
    "## UPDATE\n",
    "print(exp_name)\n",
    "tensor, tensor_d, omega=x_xd_plot_compare(data,model,size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0Q_-AN34x9SK"
   },
   "outputs": [],
   "source": [
    "# Print model's state_dict\n",
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in model_in.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
    "\n",
    "# Print optimizer's state_dict\n",
    "print(\"Optimizer's state_dict:\")\n",
    "for var_name in optimizer.state_dict():\n",
    "    print(var_name, \"\\t\", optimizer.state_dict()[var_name])\n",
    "    \n",
    "PATH=path+exp_name+'exp'+expnum+'model.pt'\n",
    "torch.save(model_in.state_dict(), PATH)\n",
    "\n",
    "###############################################################################################################################\n",
    "## UPDATE\n",
    "print(exp_name)\n",
    "tensor, tensor_d, omega=x_xd_plot_compare(data,model,size,ae=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EJnLVeltx9SO"
   },
   "outputs": [],
   "source": [
    "tensor_d_name= path+exp_name+'exp'+expnum+'_tensor_d'\n",
    "tensor_name=path+exp_name+'exp'+expnum+'_tensor'\n",
    "omega_name=path+exp_name+'exp'+expnum+'_omega'\n",
    "loss_filename=path+exp_name+'exp'+expnum+'_lossvec.csv'\n",
    "labels_filename=path+exp_name+'exp'+expnum+'_labels_test.csv'\n",
    "\n",
    "filenames=[tensor_name, tensor_d_name, omega_name]\n",
    "data_out=[]\n",
    "data_out.append(tensor)\n",
    "data_out.append(tensor_d)\n",
    "data_out.append(omega)\n",
    "\n",
    "for i in range(0,len(filenames)):\n",
    "    out_file=filenames[i]+'.csv'\n",
    "    export_tensor(data_out[i],out_file)\n",
    "np.savetxt(loss_filename, lossvec)\n",
    "np.savetxt(labels_filename, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kOMwkQXAx9SQ"
   },
   "source": [
    "### Run Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9eZHoKPPx9SR"
   },
   "outputs": [],
   "source": [
    "expnum='4'\n",
    "model_in =   Decoder_4L_6D().cuda()\n",
    "#model_in =   AE_1L50D()\n",
    "print('model loaded as cuda')\n",
    "print(model_in.parameters())\n",
    "optimizer = torch.optim.Adam(model_in.parameters(), lr=LR)\n",
    "train_loss = 0\n",
    "optimizer.zero_grad()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "code_folding": [],
    "colab": {},
    "colab_type": "code",
    "id": "5gXSwkjAx9SV",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "size=len(labels)\n",
    "start_time = time.time()\n",
    "lossvec, lossvec_cnt, model=train_decoder(EPOCH,data,model_in, optimizer,size) \n",
    "print('--- train mins %---')\n",
    "print((time.time() - start_time)/60)\n",
    "######################################\n",
    "\n",
    "###############################################################################################################################\n",
    "## UPDATE\n",
    "print(exp_name)\n",
    "tensor, tensor_d, omega=x_xd_plot_compare(data,model,size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mK4B0dGdx9Sa"
   },
   "outputs": [],
   "source": [
    "# Print model's state_dict\n",
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in model_in.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
    "\n",
    "# Print optimizer's state_dict\n",
    "print(\"Optimizer's state_dict:\")\n",
    "for var_name in optimizer.state_dict():\n",
    "    print(var_name, \"\\t\", optimizer.state_dict()[var_name])\n",
    "    \n",
    "PATH=path+exp_name+'exp'+expnum+'model.pt'\n",
    "torch.save(model_in.state_dict(), PATH)\n",
    "\n",
    "###############################################################################################################################\n",
    "## UPDATE\n",
    "print(exp_name)\n",
    "tensor, tensor_d, omega=x_xd_plot_compare(data,model,size,ae=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ajYybPkBx9Sf"
   },
   "outputs": [],
   "source": [
    "tensor_d_name=path+exp_name+'exp'+expnum+'_tensor_d'\n",
    "tensor_name=path+exp_name+'exp'+expnum+'_tensor'\n",
    "omega_name=path+exp_name+'exp'+expnum+'_omega'\n",
    "loss_filename=path+exp_name+'exp'+expnum+'_lossvec.csv'\n",
    "labels_filename=path+exp_name+'exp'+expnum+'_labels_test.csv'\n",
    "\n",
    "filenames=[tensor_name, tensor_d_name, omega_name]\n",
    "data_out=[]\n",
    "data_out.append(tensor)\n",
    "data_out.append(tensor_d)\n",
    "data_out.append(omega)\n",
    "\n",
    "for i in range(0,len(filenames)):\n",
    "    out_file=filenames[i]+'.csv'\n",
    "    export_tensor(data_out[i],out_file)\n",
    "np.savetxt(loss_filename, lossvec)\n",
    "np.savetxt(labels_filename, labels)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "j_z5-blKx9Oc",
    "l2VZpf9ex9Oj",
    "sI64h9yjx9Oo",
    "nj0L46z2x9Ot",
    "-zJVzGKTx9O3",
    "cqjsRdI2x9O8",
    "uPzC_wyHx9O9",
    "tvehBzfvx9PC",
    "sVR171Kpx9PH",
    "5_hNAaICx9PO",
    "LkGnN3bqx9PV",
    "A76FL3pox9PZ",
    "Q90Aboxrx9Pe",
    "uIRRJemtx9Pi",
    "H2sZ5fVXx9Pm",
    "EmL23qLYx9Pm",
    "VVWmWLaXx9Pq",
    "aPI_T2g6x9Pv",
    "9Sbcok7Ax9P0",
    "4R24KL9hx9P6",
    "xSJJmhaLx9P-",
    "qh_unlmRx9QD",
    "S4t3zRSyx9QH",
    "SPCY5lTwx9QR",
    "B5LToT-Gx9Qf",
    "IPg07JmHx9Qw",
    "VHJFEckfx9RY",
    "aeRceE5Mx9R3",
    "yeYjwURox9SC",
    "kOMwkQXAx9SQ"
   ],
   "name": "Experiment_GPU_2DRand_LossUpdate_Collab.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
